{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xJwVy9dVQ3I0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data ingestion preparation pipeline\n",
        "###  Data Engineer: Miguel Avila\n",
        "###  Reviewers: Luis Hermenegildo, Edgar Correa, Diego JE\n",
        "###  Proyecto Final del BootCamp Wizeline MLOPS2\n",
        "###  Equipo: mlops-equipo5 Segunda Edicion, 2024\n"
      ],
      "metadata": {
        "id": "jTPiFOPjPzTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Kaggle Library to retrieve latest version"
      ],
      "metadata": {
        "id": "qXQ5IskcQ8DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from https://www.kaggle.com/discussions/general/74235\n",
        "!pip install kaggle\n"
      ],
      "metadata": {
        "id": "wrxr4fFKXXAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Manual upload of kaggle key file"
      ],
      "metadata": {
        "id": "gwRwtVPTRSac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#run this code if we are looking into uploading a local data source\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "hK2jyVRTZN9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Variable definitions and formats"
      ],
      "metadata": {
        "id": "ZPwCkKdSRX2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define config variables\n",
        "\n",
        "src_folder = 'src_online_retail'\n",
        "src_name = 'online_retail_raw.csv'\n",
        "stg_folder = 'stg_online_retail'\n",
        "stg_name = 'online_retail_stg.csv'\n",
        "stg_rejected_name = 'online_retail_stg_rejected.csv'\n",
        "prod_folder = 'prod_online_retail'\n",
        "model_train_data = 'online_retail_train.csv'\n",
        "model_train_pct = 0.6\n",
        "model_validation_data = 'online_retail_validation.csv'\n",
        "model_validation_pct = 0.2\n",
        "model_test_data = 'online_retail_test.csv'\n",
        "model_test_pct = 0.2\n",
        "\n",
        "\n",
        "date_format = '%m/%d/%Y %H:%M'"
      ],
      "metadata": {
        "id": "KjsnQEndJJvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Connect to Kaggle using local key file and download data file"
      ],
      "metadata": {
        "id": "sz8RIqUoRjx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#EXTRACT DATA PHASE\n",
        "#connect to KAGGLE api and get raw data\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "#! kaggle datasets list\n",
        "! kaggle datasets download -d vijayuv/onlineretail\n",
        "! mkdir {src_folder}\n",
        "! mkdir {stg_folder}\n",
        "! mkdir {prod_folder}\n",
        "! unzip onlineretail.zip -d {src_folder}/\n",
        "! mv {src_folder}/OnlineRetail.csv {src_folder}/{src_name}"
      ],
      "metadata": {
        "id": "y5pqsRQ1ZbiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import needed libraries for data transformation"
      ],
      "metadata": {
        "id": "eLpV4VxYRtSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "\n",
        "\n",
        "\n",
        "### exploratory functions\n",
        "# onlineRetailDF.shape\n",
        "# onlineRetailDF.head()\n",
        "# onlineRetailDF.info()\n",
        "# onlineRetailDF.describe()\n",
        "# onlineRetailDF.isnull().sum()\n",
        "# onlineRetailDF.duplicated().sum()\n",
        "# onlineRetailDF[onlineRetailDF.duplicated()]\n",
        "# onlineRetailDF.Country.value_counts()"
      ],
      "metadata": {
        "id": "TA8KJ9xJgKFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data cleansing step, remove duplicates, nulls, negavite and other invalid values"
      ],
      "metadata": {
        "id": "V7eqRs8HR5eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from ast import Delete\n",
        "#RAW TO STG\n",
        "\n",
        "raw_online_retail_df = pd.read_csv(f'{src_folder}/{src_name}', encoding='ISO-8859-1')\n",
        "\n",
        "l_null_count = raw_online_retail_df.isnull().sum().sum()\n",
        "df_rejected_rows = pd.DataFrame()\n",
        "\n",
        "print('Starting Raw Data Processing ....')\n",
        "print('Number of nulls values in the data set :' + str(l_null_count))\n",
        "\n",
        "\n",
        "#remove nulls\n",
        "if l_null_count > 0:\n",
        "  print('Starting null removal process ...')\n",
        "  online_detail_null_df = pd.DataFrame()\n",
        "  for col in raw_online_retail_df.columns:\n",
        "      null_col_df = raw_online_retail_df[raw_online_retail_df[col].isnull()]\n",
        "      if null_col_df.shape[0] > 0:\n",
        "        online_detail_null_df = pd.concat([online_detail_null_df, null_col_df.assign(Rejection_reason = ' NULL Column value : ' + col )])\n",
        "  df_rejected_rows = online_detail_null_df\n",
        "  raw_online_retail_df.dropna(inplace=True)\n",
        "  print('Null removal process completed.')\n",
        "\n",
        "\n",
        "#remove negative quantities\n",
        "print('Starting negative quantities clean up ...')\n",
        "l_negative_count =  (raw_online_retail_df['Quantity'] < 0).sum()\n",
        "\n",
        "if l_negative_count > 0:\n",
        "  df_negative_rows = raw_online_retail_df[raw_online_retail_df['Quantity'] < 0]\n",
        "  df_rejected_rows = pd.concat([df_rejected_rows, df_negative_rows.assign(Rejection_reason = 'Negative Quantity')])\n",
        "  raw_online_retail_df.drop(raw_online_retail_df[raw_online_retail_df['Quantity'] < 0].index, inplace=True)\n",
        "\n",
        "print('Negative quantities clean up completed.')\n",
        "\n",
        "#remove invalid prices\n",
        "print('Starting invalid prices clean up ...')\n",
        "\n",
        "l_invalid_price_count =  (raw_online_retail_df['UnitPrice'] < 0.01).sum()\n",
        "\n",
        "if l_invalid_price_count > 0:\n",
        "  df_invalid_price_rows = raw_online_retail_df[raw_online_retail_df['UnitPrice'] < 0.01]\n",
        "  df_rejected_rows = pd.concat([df_rejected_rows, df_invalid_price_rows.assign(Rejection_reason = 'Invalid Price')])\n",
        "  raw_online_retail_df.drop(raw_online_retail_df[raw_online_retail_df['UnitPrice'] < 0.01].index, inplace=True)\n",
        "\n",
        "print('Invalid Prices clean up completed.')\n",
        "\n",
        "#remove invalid country values\n",
        "print('Starting Unespecified Country clean up ...')\n",
        "\n",
        "l_unspecified_country_count =  (raw_online_retail_df['Country'] == 'Unspecified').sum()\n",
        "\n",
        "if l_unspecified_country_count > 0:\n",
        "  df_unspecified_country_rows = raw_online_retail_df[raw_online_retail_df['Country'] == 'Unspecified']\n",
        "  df_rejected_rows = pd.concat([df_rejected_rows, df_unspecified_country_rows.assign(Rejection_reason = 'Unspecified')])\n",
        "  raw_online_retail_df.drop(raw_online_retail_df[raw_online_retail_df['Country'] == 'Unspecified'].index, inplace=True)\n",
        "\n",
        "print('Invalid Countries clean up completed.')\n",
        "print('End Raw Data Processing ....')\n",
        "\n",
        "pd.DataFrame.to_csv(df_rejected_rows, f'{stg_folder}/{stg_rejected_name}',index = False)\n",
        "pd.DataFrame.to_csv(raw_online_retail_df, f'{stg_folder}/{stg_name}',index = False)\n",
        "\n",
        "del df_rejected_rows\n",
        "del raw_online_retail_df"
      ],
      "metadata": {
        "id": "wRh-4qrnZG9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Standarize, normalize, format date and create new columns for easier calculations"
      ],
      "metadata": {
        "id": "2PeaoPc5SMCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "#STG TO PROD\n",
        "\n",
        "df_online_retail_stg = pd.read_csv(f'{stg_folder}/{stg_name}', encoding='ISO-8859-1')\n",
        "\n",
        "#Standarize Country Values, EIRE = Ireland, RSA = South Africa\n",
        "df_online_retail_stg.replace(to_replace='EIRE', value='Ireland', inplace=True)\n",
        "df_online_retail_stg.replace(to_replace='RSA', value='South Africa', inplace=True)\n",
        "\n",
        "#Create new columns for date calculations\n",
        "df_date_set = pd.DataFrame(pd.to_datetime(df_online_retail_stg['InvoiceDate'],format = date_format))\n",
        "df_date_set.rename(columns={'InvoiceDate':'Invoice_Date'},inplace= True)\n",
        "df_date_set['Invoice_Year'] = list(x.year for x in df_date_set['Invoice_Date'])\n",
        "df_date_set['Invoice_Month'] = list(x.month for x in df_date_set['Invoice_Date'])\n",
        "df_date_set['Invoice_Day'] = list(x.day for x in df_date_set['Invoice_Date'])\n",
        "df_date_set['Invoice_Hour'] = list(x.hour for x in df_date_set['Invoice_Date'])\n",
        "df_date_set['Invoice_Minute'] = list(x.minute for x in df_date_set['Invoice_Date'])\n",
        "\n",
        "#Standarize Descriptions\n",
        "df_online_retail_stg['Description'] = df_online_retail_stg['Description'].str.strip()\n",
        "df_online_retail_stg['Description'] = df_online_retail_stg['Description'].str.lower()\n",
        "\n",
        "#Remove duplicated column\n",
        "df_online_retail_stg = pd.concat([df_online_retail_stg, df_date_set], axis=1)\n",
        "df_online_retail_stg.drop(['InvoiceDate'], axis= 1, inplace=True)\n",
        "\n",
        "\n",
        "####################\n",
        "# Code to split processed file into training, validation and tests data sets\n",
        "\n",
        "####################\n",
        "#stg_df_len = len(df_online_retail_stg)\n",
        "#model_train_data_df, model_validation_data_df, model_test_data_df = np.split(df_online_retail_stg, [int(model_train_pct * stg_df_len), int((model_validation_pct + model_train_pct) * stg_df_len)])\n",
        "\n",
        "#pd.DataFrame.to_csv(model_train_data_df, f'{prod_folder}/{model_train_data}',index = False)\n",
        "#pd.DataFrame.to_csv(model_validation_data_df, f'{prod_folder}/{model_validation_data}',index = False)\n",
        "#pd.DataFrame.to_csv(model_test_data_df, f'{prod_folder}/{model_test_data}',index = False)\n",
        "\n",
        "#del df_online_retail_stg, model_train_data_df, model_validation_data_df, model_test_data_df\n",
        "\n",
        "#Generate single processed file\n",
        "pd.DataFrame.to_csv(df_online_retail_stg, f'{prod_folder}/online_retail_prod.csv',index = False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qZy6CoWfVW4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfec2ccf-b721-4eea-8960-c9ea3f8e3b6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.36 s, sys: 208 ms, total: 9.57 s\n",
            "Wall time: 9.77 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FRO9XhKZxh_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}